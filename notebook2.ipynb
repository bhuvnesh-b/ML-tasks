{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'ex3data1.mat'\n",
    "# we should use scipy.io for laoding the .mat file\n",
    "def read_file(file_name):\n",
    "    data = sio.loadmat(file_name)\n",
    "    X = data['X']\n",
    "    m = X.shape[0]\n",
    "    y = data['y']\n",
    "    # 0 is indexed 10 in the files (because of octave and matlab indexing system), returning it to 0...\n",
    "    y = list(y.ravel())\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 10:\n",
    "            y[i] = 0\n",
    "            \n",
    "    # matrix data is rotated CCW so we rotate it 90 degrees CW\n",
    "    for i in range(m):\n",
    "        number = X[i].reshape(20, 20)\n",
    "        number = np.rot90(number)\n",
    "        X[i] = number.ravel()\n",
    "    \n",
    "    y = np.array(y).reshape(m, 1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = read_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def h(X, theta):\n",
    "    # X is a matrix and theta is a vector, we need a vector as our answer\n",
    "    return sigmoid(np.matmul(X, theta))\n",
    "\n",
    "def single_h(x, theta):\n",
    "    # x and theta are both vectors. this function is used to simplify measuring accuracy\n",
    "    return np.matmul(theta.T, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0] # 5000, no. of training data\n",
    "n = X.shape[1] # 400, no. of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(X, y, theta):\n",
    "    m = X.shape[0]\n",
    "    # cost = (-1/m) * (yT*log(h) + (1-y)T*log(1-h))\n",
    "    first = np.matmul(y.T, np.log(h(X, theta)))\n",
    "    second = np.matmul((1 - y).T, np.log(1 - h(X, theta)))\n",
    "    return (-1 / m) * (first + second)\n",
    "\n",
    "def gradient(X, y, theta):\n",
    "    m = X.shape[0]\n",
    "    # gradient = (1/m) *  (XT*(h-y))\n",
    "    ans = np.matmul(X.T, h(X, theta) - y)\n",
    "    return (1 / m) * ans\n",
    "\n",
    "def gradient_descent(X, y, theta, iters=4000, alpha=0.01):\n",
    "    for i in range(iters):\n",
    "        theta = theta - alpha * gradient(X, y, theta)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_y(y, num):\n",
    "    m = y.shape[0]\n",
    "    y = list(y.ravel())\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        if y[i] == num:\n",
    "            y[i] = 1\n",
    "        else:\n",
    "            y[i] = 0\n",
    "    \n",
    "    return np.array(y).reshape(m, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should append a x0=1 column to our X matrix\n",
    "x0s = np.ones((m, 1))\n",
    "gd_X = np.append(x0s, X, axis=1)\n",
    "\n",
    "gd_thetas = []\n",
    "for i in range(0, 10):\n",
    "    # we are building the classifier for each digit i in each loop\n",
    "    \n",
    "    # theta is a 401x1 vector (400+1), because of x0s\n",
    "    theta = np.zeros((n+1, 1))\n",
    "    \n",
    "    # refine y to suit our current digit\n",
    "    new_y = refine_y(y, i)\n",
    "    \n",
    "    theta = gradient_descent(gd_X, new_y, theta)\n",
    "    gd_thetas.append(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient descent accuracy: %88.1\n"
     ]
    }
   ],
   "source": [
    "# comparing the prediction of our method with the real value (y)\n",
    "total = m\n",
    "corrects = 0\n",
    "\n",
    "# loop through all training data:\n",
    "for i in range(m):\n",
    "    \n",
    "    # it's ((n+1, 1)) because of x0 = 1 in gd_X\n",
    "    x = gd_X[i].ravel().reshape((n+1, 1))\n",
    "    \n",
    "    # now, for each training data, calculate the results of each classifier (we have 10 classifiers)\n",
    "    probabilities = []\n",
    "    for theta in gd_thetas:\n",
    "        prob = single_h(x, theta)\n",
    "        probabilities.append(prob)\n",
    "    \n",
    "\n",
    "    prediction_prob = max(probabilities)\n",
    "    \n",
    "    number_predicted = probabilities.index(prediction_prob)\n",
    "    \n",
    "    if number_predicted == y[i][0]:\n",
    "        corrects += 1\n",
    "\n",
    "print('Gradient descent accuracy: %{0}'.format(100 * corrects / m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhuvnesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Bhuvnesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Bhuvnesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Bhuvnesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "regressors = []\n",
    "for i in range(0, 10):\n",
    "    regressor = LogisticRegression()\n",
    "    \n",
    "    # refine y to suit our current digit\n",
    "    new_y = refine_y(y, i)\n",
    "    \n",
    "    # sklearn accepts a 1d array as y so we ravel() the vector\n",
    "    regressor.fit(X, new_y.ravel())\n",
    "    regressors.append(regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit learn accuracy: %86.56\n"
     ]
    }
   ],
   "source": [
    "# comparing the prediction of our method with the real value (y)\n",
    "total = m\n",
    "corrects = 0\n",
    "\n",
    "# loop through all training data:\n",
    "for i in range(m):\n",
    "    # sklearn accepts 2d array as input to predict\n",
    "    x = [X[i]]\n",
    "    \n",
    "    # now, for each training data, calculate the results of each classifier (we have 10 classifiers)\n",
    "    predictions = []\n",
    "    for regressor in regressors:\n",
    "        prediction = regressor.predict(x)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    try:\n",
    "        number_predicted = predictions.index(1)\n",
    "    except: \n",
    "        number_predicted = -1\n",
    "    \n",
    "    if number_predicted == y[i][0] and predictions.count(1) == 1:\n",
    "        corrects += 1\n",
    "\n",
    "print('Scikit learn accuracy: %{0}'.format(100 * corrects / m))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d47b27e9d4ccec73555efdbe9cd0c6dffcb176c278806a4161671a33d47d1c5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
